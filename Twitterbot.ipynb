{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitterbot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/minxdragon/MyTwitterBot/blob/master/Twitterbot.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "AVyZs6mkUwJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "34fa9628-8f7a-4b39-e003-e28b72a1a9a3"
      },
      "cell_type": "code",
      "source": [
        "#get the repo from github\n",
        "!git clone https://github.com/minxdragon/MyTwitterBot.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MyTwitterBot'...\n",
            "remote: Counting objects: 281, done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 281 (delta 0), reused 0 (delta 0), pack-reused 276\u001b[K\n",
            "Receiving objects: 100% (281/281), 9.34 MiB | 27.49 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sHrkYxvAYr7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1117
        },
        "outputId": "e40d88df-7ba9-4e4a-e255-6537c6ea1a3b"
      },
      "cell_type": "code",
      "source": [
        "#install the reqquirements\n",
        "!pip3 install -r MyTwitterBot/requirements.txt\n",
        "!pip3 install numpy\n",
        "!python -m pip install pandas==0.21.0 --force-reinstall --upgrade --no-deps --no-cache --find-links https://3f23b170c54c2533c070-1c8a9b3114517dc5fe17b7c3f8c63a43.ssl.cf2.rackcdn.com/ --no-index"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.12.1 (from -r MyTwitterBot/requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/e2/884cfbfd4f21b2313210d1d2ea72ecc381b98826d1b7e6606929ac6c0a08/numpy-1.12.1-cp36-cp36m-manylinux1_x86_64.whl (16.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 16.8MB 1.3MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.2.1 (from -r MyTwitterBot/requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/d0/96269b9ecfcc55cb38779831595e0521c34ef4ecdeba08b1ba4194cc4813/tensorflow-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 35.0MB 979kB/s \n",
            "\u001b[?25hCollecting textblob==0.12.0 (from -r MyTwitterBot/requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/33/6216b8d4cfa4390541b0a1ac4c04b7ab10b30b350d684dc02d5e428f0821/textblob-0.12.0-py2.py3-none-any.whl (631kB)\n",
            "\u001b[K    100% |████████████████████████████████| 634kB 28.4MB/s \n",
            "\u001b[?25hCollecting tweepy==3.5.0 (from -r MyTwitterBot/requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/8f/167f956350f4e6098e699d2b6f99192cc22971b40624a0f3b8011b4e9f38/tweepy-3.5.0-py2.py3-none-any.whl\n",
            "Collecting pandas==0.19.1 (from -r MyTwitterBot/requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/9c/20a36af2016a9554378ebad2c69f63fd87bd0cc612eeed068fab656ec661/pandas-0.19.1.tar.gz (8.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 8.4MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests_oauthlib==0.8.0 in /usr/local/lib/python3.6/dist-packages (from -r MyTwitterBot/requirements.txt (line 6)) (0.8.0)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1->-r MyTwitterBot/requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1->-r MyTwitterBot/requirements.txt (line 2)) (0.31.1)\n",
            "Collecting backports.weakref==1.0rc1 (from tensorflow==1.2.1->-r MyTwitterBot/requirements.txt (line 2))\n",
            "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1->-r MyTwitterBot/requirements.txt (line 2)) (2.6.11)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1->-r MyTwitterBot/requirements.txt (line 2)) (0.9999999)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1->-r MyTwitterBot/requirements.txt (line 2)) (0.14.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1->-r MyTwitterBot/requirements.txt (line 2)) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1->-r MyTwitterBot/requirements.txt (line 2)) (3.5.2.post1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob==0.12.0->-r MyTwitterBot/requirements.txt (line 3)) (3.2.5)\n",
            "Requirement already satisfied: requests>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from tweepy==3.5.0->-r MyTwitterBot/requirements.txt (line 4)) (2.18.4)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.19.1->-r MyTwitterBot/requirements.txt (line 5)) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.19.1->-r MyTwitterBot/requirements.txt (line 5)) (2018.4)\n",
            "Requirement already satisfied: oauthlib>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from requests_oauthlib==0.8.0->-r MyTwitterBot/requirements.txt (line 6)) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.2.1->-r MyTwitterBot/requirements.txt (line 2)) (39.2.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.4.3->tweepy==3.5.0->-r MyTwitterBot/requirements.txt (line 4)) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.4.3->tweepy==3.5.0->-r MyTwitterBot/requirements.txt (line 4)) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.4.3->tweepy==3.5.0->-r MyTwitterBot/requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.4.3->tweepy==3.5.0->-r MyTwitterBot/requirements.txt (line 4)) (1.22)\n",
            "Building wheels for collected packages: pandas\n",
            "  Running setup.py bdist_wheel for pandas ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d4/01/aa/e00a20b4c9ed4870d6df7a9aa534817861611196ecfd32a685\n",
            "Successfully built pandas\n",
            "Installing collected packages: numpy, backports.weakref, tensorflow, textblob, tweepy, pandas\n",
            "  Found existing installation: numpy 1.14.3\n",
            "    Uninstalling numpy-1.14.3:\n",
            "      Successfully uninstalled numpy-1.14.3\n",
            "  Found existing installation: tensorflow 1.8.0\n",
            "    Uninstalling tensorflow-1.8.0:\n",
            "      Successfully uninstalled tensorflow-1.8.0\n",
            "  Found existing installation: pandas 0.22.0\n",
            "    Uninstalling pandas-0.22.0:\n",
            "      Successfully uninstalled pandas-0.22.0\n",
            "Successfully installed backports.weakref-1.0rc1 numpy-1.12.1 pandas-0.19.1 tensorflow-1.2.1 textblob-0.12.0 tweepy-3.5.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.12.1)\n",
            "Looking in links: https://3f23b170c54c2533c070-1c8a9b3114517dc5fe17b7c3f8c63a43.ssl.cf2.rackcdn.com/\n",
            "Collecting pandas==0.21.0\n",
            "\u001b[?25l  Downloading https://3f23b170c54c2533c070-1c8a9b3114517dc5fe17b7c3f8c63a43.ssl.cf2.rackcdn.com/pandas-0.21.0-cp36-cp36m-manylinux1_x86_64.whl (26.2MB)\n",
            "\u001b[K    41% |█████████████▍                  | 10.9MB 4.6MB/s eta 0:00:04"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 26.2MB 3.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Found existing installation: pandas 0.19.1\n",
            "    Uninstalling pandas-0.19.1:\n",
            "      Successfully uninstalled pandas-0.19.1\n",
            "Successfully installed pandas-0.21.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c70mlWYKaiTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "81aac7e8-59de-4d2f-d576-ec5adad8133e"
      },
      "cell_type": "code",
      "source": [
        "#download the nltk data\n",
        "!python -m textblob.download_corpora"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /content/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ufapYxEMVIRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1295
        },
        "outputId": "562842f0-0d70-478a-f87c-f54e64c27900"
      },
      "cell_type": "code",
      "source": [
        "#testing testing 123\n",
        "!python3 MyTwitterBot/src/test/test_all.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "=== Running test for the text manipulation functions ===\r\n",
            "\r\n",
            "test_clean_and_cut (TextManiTest.TextManiTest) ... ok\n",
            "test_cleaning (TextManiTest.TextManiTest) ... ok\n",
            "test_cutting (TextManiTest.TextManiTest) ... ok\n",
            "test_enco_deco (TextManiTest.TextManiTest) ... 645 total tokens with 347 uniques\n",
            "ok\n",
            "test_eos (TextManiTest.TextManiTest) ... 645 total tokens with 347 uniques\n",
            "ok\n",
            "test_len_text (TextManiTest.TextManiTest) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 6 tests in 0.010s\n",
            "\n",
            "OK\n",
            "\n",
            "=== Running test for the RNN model ===\n",
            "\n",
            "929589 total tokens with 10000 uniques\n",
            "test_otimization (RNNTest.RNNTest) ... 2018-06-06 10:51:41.762514: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2018-06-06 10:51:41.762559: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2018-06-06 10:51:41.762579: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2018-06-06 10:51:41.762596: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2018-06-06 10:51:41.762615: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
            "ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 53.117s\n",
            "\n",
            "OK\n",
            "\n",
            "=== Running test for the generate functions ===\n",
            "\n",
            "929589 total tokens with 10000 uniques\n",
            "ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 36.996s\n",
            "\n",
            "OK\n",
            "\n",
            "=== Running test for tweet generation ===\n",
            "\n",
            "test_tweet_hashtags_content (TweetGeneratorTest.TweetGeneratorTest) ... 929589 total tokens with 10000 uniques\n",
            "==Training the model==\n",
            "Epoch 0\n",
            "Training perplexity: 9938.2041015625\n",
            "Validation perplexity: 8376.1689453125\n",
            "Total time: 1.5367462635040283\n",
            "ok\n",
            "test_tweet_size (TweetGeneratorTest.TweetGeneratorTest) ... 929589 total tokens with 10000 uniques\n",
            "==Training the model==\n",
            "Epoch 0\n",
            "Training perplexity: 10448.1767578125\n",
            "Validation perplexity: 8827.78125\n",
            "Total time: 1.4941964149475098\n",
            "ok\n",
            "test_tweet_size_hashtags (TweetGeneratorTest.TweetGeneratorTest) ... 929589 total tokens with 10000 uniques\n",
            "==Training the model==\n",
            "Epoch 0\n",
            "Training perplexity: 10225.279296875\n",
            "Validation perplexity: 8846.103515625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Total time: 1.5228066444396973\n",
            "ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 20.453s\n",
            "\n",
            "OK\n",
            "The test for the Twitter Bot was not executed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D8-vd8hLcrvj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "c1e85d96-805a-486c-8e6f-37d6c4ff6617"
      },
      "cell_type": "code",
      "source": [
        "#train the RNN - upfate the path to the training data if you want to use something \n",
        "#other than trumps bullshit\n",
        "! python3 MyTwitterBot/src/tutorials/TrumpBot/train.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "447279 total tokens with 21922 uniques\n",
            "2018-06-06 10:15:16.401643: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2018-06-06 10:15:16.401697: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2018-06-06 10:15:16.401720: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2018-06-06 10:15:16.401749: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2018-06-06 10:15:16.401791: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
            "Epoch 0\n",
            "70 / 307 : pp = 1442.29052734375"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zCt9UO-wHWi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "761c7b29-934f-451b-bb8e-dea93f039b60"
      },
      "cell_type": "code",
      "source": [
        "#write the tweets\n",
        "!python3 MyTwitterBot/src/tutorials/TrumpBot/write.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\r\n",
            "  File \"/content/MyTwitterBot/src/agent/Bot.py\", line 7, in <module>\r\n",
            "    from key import ConsumerKey, ConsumerSecret\r\n",
            "ModuleNotFoundError: No module named 'key'\r\n",
            "\r\n",
            "During handling of the above exception, another exception occurred:\r\n",
            "\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"MyTwitterBot/src/tutorials/TrumpBot/write.py\", line 12, in <module>\r\n",
            "    from agent.Bot import Bot\r\n",
            "  File \"/content/MyTwitterBot/src/agent/Bot.py\", line 10, in <module>\r\n",
            "    from agent.key import ConsumerKey, ConsumerSecret\r\n",
            "ModuleNotFoundError: No module named 'agent.key'\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wm-eHA5JIEvu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 usr/local/lib/python3.6/setup.py build_ext --inplace --force"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UJJCzeSDLbAJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}